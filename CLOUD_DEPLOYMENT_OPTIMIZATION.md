# Cloud Deployment & Performance Optimization Guide

## Current System Analysis

### üîç **Performance Bottlenecks Identified:**

1. **Database Layer**
   - ‚ùå SQLite (single-file, not horizontally scalable)
   - ‚ùå No connection pooling
   - ‚ùå No database indexing optimization
   - ‚ùå Synchronous I/O operations

2. **File Storage**
   - ‚ùå Local file system storage
   - ‚ùå No CDN for file delivery
   - ‚ùå Large file uploads block the main thread
   - ‚ùå No file compression or optimization

3. **AI Processing**
   - ‚ùå Synchronous document analysis
   - ‚ùå Single-threaded processing
   - ‚ùå No caching of analysis results
   - ‚ùå Heavy CPU/memory usage for large documents

4. **Application Architecture**
   - ‚ùå Single Flask instance (not scalable)
   - ‚ùå No load balancing
   - ‚ùå No caching layer
   - ‚ùå No background job processing

## üöÄ **Cloud-Optimized Architecture**

### **Tier 1: Basic Cloud Deployment (Quick Wins)**

#### 1. **Database Migration**
```python
# Replace SQLite with PostgreSQL
DATABASE_CONFIG = {
    'engine': 'postgresql',
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 5432)),
    'database': os.getenv('DB_NAME', 'fertivision'),
    'username': os.getenv('DB_USER', 'fertivision_user'),
    'password': os.getenv('DB_PASSWORD'),
    'pool_size': 20,
    'max_overflow': 30,
    'pool_timeout': 30,
    'pool_recycle': 3600
}
```

#### 2. **Cloud Storage Integration**
```python
# AWS S3 / Google Cloud Storage / Azure Blob
CLOUD_STORAGE_CONFIG = {
    'provider': 'aws_s3',  # or 'gcp_storage', 'azure_blob'
    'bucket_name': 'fertivision-documents',
    'region': 'us-east-1',
    'access_key': os.getenv('AWS_ACCESS_KEY_ID'),
    'secret_key': os.getenv('AWS_SECRET_ACCESS_KEY'),
    'cdn_domain': 'cdn.fertivision.com'
}
```

#### 3. **Container Deployment**
```dockerfile
# Dockerfile for cloud deployment
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libpq-dev \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Use Gunicorn for production
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "--timeout", "120", "app:app"]
```

### **Tier 2: Performance Optimization**

#### 1. **Asynchronous Processing with Celery**
```python
# celery_tasks.py
from celery import Celery
import redis

# Configure Celery with Redis
celery_app = Celery(
    'fertivision',
    broker='redis://redis:6379/0',
    backend='redis://redis:6379/0'
)

@celery_app.task
def analyze_document_async(patient_id, file_path, document_type):
    """Asynchronous document analysis"""
    try:
        # Perform heavy AI analysis in background
        analyzer = DocumentAnalyzer()
        result = analyzer.analyze_document(file_path, document_type)
        
        # Update patient record with results
        patient_manager = PatientHistoryManager()
        patient_manager.update_document_analysis(patient_id, result)
        
        return {
            'status': 'completed',
            'document_id': result.document_id,
            'confidence': result.confidence_score
        }
    except Exception as e:
        return {'status': 'failed', 'error': str(e)}

@celery_app.task
def generate_pdf_report_async(patient_id):
    """Asynchronous PDF generation"""
    try:
        patient_manager = PatientHistoryManager()
        pdf_path = patient_manager.generate_pdf_report(patient_id)
        
        # Upload to cloud storage
        cloud_url = upload_to_cloud_storage(pdf_path)
        
        return {
            'status': 'completed',
            'pdf_url': cloud_url
        }
    except Exception as e:
        return {'status': 'failed', 'error': str(e)}
```

#### 2. **Caching Layer with Redis**
```python
# caching.py
import redis
import json
import hashlib
from functools import wraps

redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=0,
    decode_responses=True
)

def cache_result(expiration=3600):
    """Decorator to cache function results"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Create cache key
            cache_key = f"{func.__name__}:{hashlib.md5(str(args).encode()).hexdigest()}"
            
            # Try to get from cache
            cached_result = redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)
            
            # Execute function and cache result
            result = func(*args, **kwargs)
            redis_client.setex(cache_key, expiration, json.dumps(result))
            
            return result
        return wrapper
    return decorator

# Usage in patient_history.py
@cache_result(expiration=1800)  # Cache for 30 minutes
def calculate_fertility_score(self, patient_id):
    # Expensive fertility calculation
    pass
```

#### 3. **Database Optimization**
```python
# optimized_db.py
import sqlalchemy
from sqlalchemy import create_engine, Index
from sqlalchemy.pool import QueuePool

class OptimizedDatabase:
    def __init__(self):
        # Connection pooling
        self.engine = create_engine(
            DATABASE_URL,
            poolclass=QueuePool,
            pool_size=20,
            max_overflow=30,
            pool_timeout=30,
            pool_recycle=3600,
            echo=False  # Disable SQL logging in production
        )
        
        # Create optimized indexes
        self.create_indexes()
    
    def create_indexes(self):
        """Create database indexes for performance"""
        with self.engine.connect() as conn:
            # Index on patient_id for quick lookups
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_patients_id 
                ON patients(patient_id)
            """))
            
            # Index on medical_record_number for searches
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_patients_medical_id 
                ON patients(medical_record_number)
            """))
            
            # Index on document patient_id for joins
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_documents_patient_id 
                ON documents(patient_id)
            """))
            
            # Index on created_date for sorting
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_patients_created_date 
                ON patients(created_date DESC)
            """))

    def get_patients_paginated(self, page=1, per_page=20):
        """Paginated patient retrieval"""
        offset = (page - 1) * per_page
        with self.engine.connect() as conn:
            result = conn.execute(text("""
                SELECT * FROM patients 
                ORDER BY created_date DESC 
                LIMIT :limit OFFSET :offset
            """), {"limit": per_page, "offset": offset})
            return result.fetchall()
```

### **Tier 3: Microservices Architecture**

#### 1. **Service Decomposition**
```yaml
# docker-compose.yml for microservices
version: '3.8'
services:
  # API Gateway
  api-gateway:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - patient-service
      - document-service
      - analysis-service

  # Patient Management Service
  patient-service:
    build: ./services/patient-service
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/patients
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - postgres
      - redis

  # Document Processing Service
  document-service:
    build: ./services/document-service
    environment:
      - AWS_S3_BUCKET=fertivision-documents
      - CELERY_BROKER=redis://redis:6379/1
    depends_on:
      - redis
      - minio

  # AI Analysis Service
  analysis-service:
    build: ./services/analysis-service
    environment:
      - OLLAMA_URL=http://ollama:11434
      - MODEL_CACHE_DIR=/models
    volumes:
      - model-cache:/models
    depends_on:
      - ollama
      - redis

  # Databases
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: fertivision
      POSTGRES_USER: fertivision_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres-data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data

  # Object Storage (MinIO as S3 alternative)
  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data

  # AI Model Service
  ollama:
    image: ollama/ollama
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_MODELS=deepseek-coder

  # Background Job Workers
  celery-worker:
    build: ./services/document-service
    command: celery -A celery_app worker --loglevel=info --concurrency=4
    depends_on:
      - redis
      - postgres

  # Job Monitoring
  flower:
    build: ./services/document-service
    command: celery -A celery_app flower
    ports:
      - "5555:5555"
    depends_on:
      - redis

volumes:
  postgres-data:
  redis-data:
  minio-data:
  ollama-data:
  model-cache:
```

#### 2. **Load Balancing Configuration**
```nginx
# nginx.conf
upstream patient_service {
    server patient-service:8000;
    server patient-service:8001;
    server patient-service:8002;
}

upstream document_service {
    server document-service:8000;
    server document-service:8001;
}

upstream analysis_service {
    server analysis-service:8000;
    server analysis-service:8001;
}

server {
    listen 80;
    server_name api.fertivision.com;

    # Patient API
    location /api/patients {
        proxy_pass http://patient_service;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }

    # Document API
    location /api/documents {
        proxy_pass http://document_service;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        client_max_body_size 50M;  # Large file uploads
        proxy_connect_timeout 60s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
    }

    # Analysis API
    location /api/analysis {
        proxy_pass http://analysis_service;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 60s;
        proxy_send_timeout 600s;  # Long AI processing
        proxy_read_timeout 600s;
    }

    # Static files from CDN
    location /static {
        expires 1y;
        add_header Cache-Control "public, immutable";
        proxy_pass https://cdn.fertivision.com;
    }
}
```

### **Tier 4: Auto-Scaling & Monitoring**

#### 1. **Kubernetes Deployment**
```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: patient-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: patient-service
  template:
    metadata:
      labels:
        app: patient-service
    spec:
      containers:
      - name: patient-service
        image: fertivision/patient-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: patient-service
spec:
  selector:
    app: patient-service
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: patient-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: patient-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### 2. **Monitoring & Observability**
```python
# monitoring.py
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge
import time
import logging

# Metrics
REQUEST_COUNT = Counter('fertivision_requests_total', 'Total requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('fertivision_request_duration_seconds', 'Request duration')
ACTIVE_PATIENTS = Gauge('fertivision_active_patients_total', 'Total active patients')
DOCUMENT_PROCESSING_TIME = Histogram('fertivision_document_processing_seconds', 'Document processing time')

def monitor_performance(func):
    """Decorator to monitor function performance"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='success').inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(method='POST', endpoint=func.__name__, status='error').inc()
            raise
        finally:
            REQUEST_DURATION.observe(time.time() - start_time)
    return wrapper

# Health check endpoints
@app.route('/health')
def health_check():
    """Health check for load balancer"""
    try:
        # Check database connection
        db.execute('SELECT 1')
        
        # Check Redis connection
        redis_client.ping()
        
        return jsonify({'status': 'healthy', 'timestamp': time.time()})
    except Exception as e:
        return jsonify({'status': 'unhealthy', 'error': str(e)}), 503

@app.route('/metrics')
def metrics():
    """Prometheus metrics endpoint"""
    return prometheus_client.generate_latest()
```

## üåê **Cloud Provider Specific Recommendations**

### **AWS Deployment**
```yaml
# AWS-specific optimizations
Services:
  - RDS PostgreSQL (Multi-AZ for HA)
  - ElastiCache Redis (Cluster mode)
  - S3 + CloudFront CDN
  - ECS Fargate (serverless containers)
  - Application Load Balancer
  - Lambda (for PDF generation)
  - SQS (message queuing)
  - CloudWatch (monitoring)

Estimated Monthly Cost: $500-$2000 (depending on scale)
```

### **Google Cloud Platform**
```yaml
# GCP-specific optimizations
Services:
  - Cloud SQL PostgreSQL (HA)
  - Memorystore Redis
  - Cloud Storage + Cloud CDN
  - Cloud Run (serverless)
  - Cloud Load Balancing
  - Cloud Functions (PDF generation)
  - Pub/Sub (messaging)
  - Cloud Monitoring

Estimated Monthly Cost: $400-$1800 (depending on scale)
```

### **Azure Deployment**
```yaml
# Azure-specific optimizations
Services:
  - Azure Database for PostgreSQL
  - Azure Cache for Redis
  - Azure Blob Storage + Azure CDN
  - Azure Container Instances
  - Azure Load Balancer
  - Azure Functions (PDF generation)
  - Service Bus (messaging)
  - Azure Monitor

Estimated Monthly Cost: $450-$1900 (depending on scale)
```

## üìä **Performance Benchmarks**

### **Before Optimization (Current)**
- üêå **Concurrent Users**: ~10-20
- üêå **Response Time**: 2-5 seconds
- üêå **Document Processing**: 30-60 seconds
- üêå **Database Queries**: 100-500ms
- üêå **File Upload**: Limited by server storage

### **After Cloud Optimization**
- üöÄ **Concurrent Users**: 1000-5000+
- üöÄ **Response Time**: 100-300ms
- üöÄ **Document Processing**: 5-15 seconds (async)
- üöÄ **Database Queries**: 10-50ms
- üöÄ **File Upload**: Unlimited (cloud storage)

## üéØ **Implementation Roadmap**

### **Phase 1: Basic Cloud Migration (Week 1-2)**
1. ‚úÖ Containerize application
2. ‚úÖ Migrate to PostgreSQL
3. ‚úÖ Deploy to cloud with basic auto-scaling
4. ‚úÖ Implement cloud storage for files

### **Phase 2: Performance Optimization (Week 3-4)**
1. ‚úÖ Add Redis caching layer
2. ‚úÖ Implement async document processing
3. ‚úÖ Add database indexing and optimization
4. ‚úÖ Set up CDN for static content

### **Phase 3: Microservices (Week 5-8)**
1. ‚úÖ Split into microservices
2. ‚úÖ Implement API gateway
3. ‚úÖ Add load balancing
4. ‚úÖ Set up monitoring and logging

### **Phase 4: Advanced Features (Week 9-12)**
1. ‚úÖ Implement auto-scaling
2. ‚úÖ Add comprehensive monitoring
3. ‚úÖ Set up CI/CD pipelines
4. ‚úÖ Implement disaster recovery

This cloud-optimized architecture will handle thousands of concurrent users and process documents efficiently at scale! üöÄ
